<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="description" content="Prediction Assignment - Writeup : This GitHub repository corresponds to the Course Project of the Practical Machine Learning course of the Data Science Specialization offered by Bloomberg School of Public Health of the Johns Hopkins University through Coursera.">

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>Prediction Assignment - Writeup</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.com/abhishekumrawal/PredictionAssignment-WriteUp">View on GitHub</a>

          <h1 id="project_title">Prediction Assignment - Writeup</h1>
          <h2 id="project_tagline">This GitHub repository corresponds to the Course Project of the Practical Machine Learning course of the Data Science Specialization offered by Bloomberg School of Public Health of the Johns Hopkins University through Coursera.</h2>

            <section id="downloads">
              <a class="zip_download_link" href="https://github.com/abhishekumrawal/PredictionAssignment-WriteUp/zipball/master">Download this project as a .zip file</a>
              <a class="tar_download_link" href="https://github.com/abhishekumrawal/PredictionAssignment-WriteUp/tarball/master">Download this project as a tar.gz file</a>
            </section>
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        <hr>

<p>title: "Prediction Assignment Writeup"
author: "Abhishek Umrawal"</p>

<h2>
<a id="output-html_document" class="anchor" href="#output-html_document" aria-hidden="true"><span class="octicon octicon-link"></span></a>output: html_document</h2>

<h1>
<a id="1-introduction" class="anchor" href="#1-introduction" aria-hidden="true"><span class="octicon octicon-link"></span></a>1. Introduction</h1>

<p>The project involves solving a <em>Classification Problem</em> (Predicting the Class based on some Independent Variables.)</p>

<p>We have been provided the data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. </p>

<p>More information is available from the website here: <a href="http://groupware.les.inf.puc-rio.br/har">http://groupware.les.inf.puc-rio.br/har</a> (see the section on the Weight Lifting Exercise Dataset).</p>

<p>The problem is approached through the following the three steps: </p>

<p>1.1 Pre-Processing of Data (Discussing the Approach I have taken.)</p>

<p>1.2 Learning the Clasification Hypothesis using the Training Data</p>

<p>1.3 Using the Learned Model for Predicting Classification for the Testing Data</p>

<h1>
<a id="2-pre-processing-of-data" class="anchor" href="#2-pre-processing-of-data" aria-hidden="true"><span class="octicon octicon-link"></span></a>2. Pre-Processing of Data</h1>

<p>We have first identified the variables which are present in the testing data and then removed all those variables from the training data as well which are not in the testing data, as the final prediction is to be done for the testing data.</p>

<p>Also there was a categorical variable named as <em>new_window</em> whihch takes values either <em>yes</em> or <em>no</em>, we have recoded them as <em>1</em> and <em>0</em> respectively.</p>

<h1>
<a id="3-learning-the-clasification-hypothesis-using-the-training-data" class="anchor" href="#3-learning-the-clasification-hypothesis-using-the-training-data" aria-hidden="true"><span class="octicon octicon-link"></span></a>3. Learning the Clasification Hypothesis using the Training Data</h1>

<p>We need to learn a Classification hypothesis using the training data. Several algorithms like Classification Tree, Random Forests, ADA Boosting etc. have been introduced in the lectures. We are making use of the Classification Tree Algorithm for this purpose. </p>

<p>Learning a Classification Tree for the Training Data:</p>

<div class="highlight highlight-r"><pre><span class="pl-c">#Reading Training and Test Data.</span>
<span class="pl-vo">training</span><span class="pl-k">&lt;-</span>read.csv(<span class="pl-s1"><span class="pl-pds">"</span>pml-training.csv<span class="pl-pds">"</span></span>,<span class="pl-v">header</span><span class="pl-k">=</span><span class="pl-c1">TRUE</span>)
<span class="pl-vo">testing</span><span class="pl-k">&lt;-</span>read.csv(<span class="pl-s1"><span class="pl-pds">"</span>pml-testing.csv<span class="pl-pds">"</span></span>,<span class="pl-v">header</span><span class="pl-k">=</span><span class="pl-c1">TRUE</span>)

<span class="pl-c">#Including the Necessary Library rpart</span>
library(<span class="pl-vo">rpart</span>)

<span class="pl-c">#Fitting the Model</span>
<span class="pl-vo">fit</span> <span class="pl-k">&lt;-</span> rpart(<span class="pl-vo">classe</span> <span class="pl-k">~</span>.,<span class="pl-v">method</span><span class="pl-k">=</span><span class="pl-s1"><span class="pl-pds">"</span>class<span class="pl-pds">"</span></span>, <span class="pl-v">data</span><span class="pl-k">=</span><span class="pl-vo">training</span>)</pre></div>

<div class="highlight highlight-r"><pre><span class="pl-c"># Displaying the Model Results</span>
printcp(<span class="pl-vo">fit</span>)

<span class="pl-c"># Visualizing Cross-Validation Results</span>
plotcp(<span class="pl-vo">fit</span>)  

<span class="pl-c"># Detailed Summary of Splits</span>
summary(<span class="pl-vo">fit</span>) </pre></div>

<h2>
<a id="assessing-the-performance-of-model-on-the-training-data" class="anchor" href="#assessing-the-performance-of-model-on-the-training-data" aria-hidden="true"><span class="octicon octicon-link"></span></a>Assessing the Performance of Model on the Training Data</h2>

<h2>
<a id="31-confusion-matrix" class="anchor" href="#31-confusion-matrix" aria-hidden="true"><span class="octicon octicon-link"></span></a>3.1. Confusion Matrix</h2>

<pre><code>## 
##    Cell Contents
## |-------------------------|
## |                   Count |
## |-------------------------|
## 
## Total Observations in Table:  19622 
## 
##                | Predicted_Class 
## Observed_Class |        A  |        B  |        C  |        D  |        E  | Row Total | 
## ---------------|-----------|-----------|-----------|-----------|-----------|-----------|
##              A |     4970  |      636  |      128  |      201  |      179  |     6114  | 
## ---------------|-----------|-----------|-----------|-----------|-----------|-----------|
##              B |      175  |     2336  |      243  |      279  |      398  |     3431  | 
## ---------------|-----------|-----------|-----------|-----------|-----------|-----------|
##              C |       59  |      244  |     2772  |      469  |      288  |     3832  | 
## ---------------|-----------|-----------|-----------|-----------|-----------|-----------|
##              D |      299  |      461  |      189  |     2120  |      424  |     3493  | 
## ---------------|-----------|-----------|-----------|-----------|-----------|-----------|
##              E |       77  |      120  |       90  |      147  |     2318  |     2752  | 
## ---------------|-----------|-----------|-----------|-----------|-----------|-----------|
##   Column Total |     5580  |     3797  |     3422  |     3216  |     3607  |    19622  | 
## ---------------|-----------|-----------|-----------|-----------|-----------|-----------|
## 
## 
</code></pre>

<h2>
<a id="32-visualizing-cross-validation-results-and-expected-out-of-sample-error" class="anchor" href="#32-visualizing-cross-validation-results-and-expected-out-of-sample-error" aria-hidden="true"><span class="octicon octicon-link"></span></a>3.2 Visualizing Cross-Validation Results and Expected Out of Sample Error</h2>

<p>Cross-Validation Results plot is as follows:</p>

<p><img src="figure/unnamed-chunk-4.png" alt="plot of chunk unnamed-chunk-4"> </p>

<p>We use the <strong>Percentage of Misclassification in Cross-Validation</strong> as an estimate of expected out of sample error. The percentage of misclassification turns out to be 26.02%. So the model can be taken as of good adequacy.</p>

<h1>
<a id="4-using-the-learned-model-for-predicting-classification-for-the-testing-data" class="anchor" href="#4-using-the-learned-model-for-predicting-classification-for-the-testing-data" aria-hidden="true"><span class="octicon octicon-link"></span></a>4. Using the Learned Model for Predicting Classification for the Testing Data</h1>

<p>Now we make use of the developed classification model to predict the classes for the testing data. The testing data has 20 observations and we need to predict the class of each of the observations.</p>

<p>Using the learned model we obtain the probabilities for each observation belonging to each of the 5 classes viz. A, B, C, D and E. The class for which an observation has the maximum probability we classify that observation into that class.</p>

<p>We get the following table representing individual probabilities and the predicted classes for each of the observations in the testing data.:</p>

<pre><code>##    Obs Prob.A.   Prob.B. Prob.C. Prob.D.  Prob.E. Predicted.Class
## 1    1 0.09884 0.5465116 0.00000 0.00000 0.354651               B
## 2    2 0.77892 0.1745574 0.01359 0.02676 0.006175               A
## 3    3 0.01396 0.5340314 0.22862 0.10122 0.122164               B
## 4    4 0.83483 0.0007508 0.00000 0.06156 0.102853               A
## 5    5 0.83483 0.0007508 0.00000 0.06156 0.102853               A
## 6    6 0.02394 0.0819473 0.11684 0.17769 0.599594               E
## 7    7 0.06650 0.1240409 0.03581 0.69693 0.076726               D
## 8    8 0.12406 0.5243596 0.07986 0.12657 0.145153               B
## 9    9 0.99366 0.0063371 0.00000 0.00000 0.000000               A
## 10  10 0.77892 0.1745574 0.01359 0.02676 0.006175               A
## 11  11 0.02394 0.5995943 0.08195 0.17769 0.116836               B
## 12  12 0.01396 0.2286213 0.53403 0.10122 0.122164               C
## 13  13 0.02394 0.5995943 0.08195 0.17769 0.116836               B
## 14  14 0.99366 0.0063371 0.00000 0.00000 0.000000               A
## 15  15 0.07636 0.1454545 0.10909 0.17818 0.490909               E
## 16  16 0.12406 0.1265696 0.52436 0.07986 0.145153               B
## 17  17 0.83483 0.0007508 0.00000 0.06156 0.102853               A
## 18  18 0.10744 0.4008264 0.01033 0.33058 0.150826               B
## 19  19 0.10744 0.4008264 0.01033 0.33058 0.150826               B
## 20  20 0.01396 0.5340314 0.22862 0.10122 0.122164               B
</code></pre>

<h1>
<a id="5-conclusion" class="anchor" href="#5-conclusion" aria-hidden="true"><span class="octicon octicon-link"></span></a>5. Conclusion</h1>

<p>The classification model learned using the training data works decently well for both training and testing sets indicating the adequacy of fitting strength and predictive strength of the model.</p>

<p>However other classification algorithms like Random Forest, ADA Boost etc. can also be utilized for the same problem.</p>
      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p class="copyright">Prediction Assignment - Writeup maintained by <a href="https://github.com/abhishekumrawal">abhishekumrawal</a></p>
        <p>Published with <a href="http://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>

    

  </body>
</html>
